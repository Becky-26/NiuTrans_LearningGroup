# data parallel

* [Distributed Deep Learning, Part 1: An Introduction to Distributed Training of Neural Networks](http://engineering.skymind.io/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks)
     
    本文介绍如何分布地训练神经网络，主要介绍数据并行的各种方法，包括同步、异步、参数平均、梯度累加，是多设备训练神经网络很好的一篇入门博客。<br>
    tag：数据并行；多机多卡；入门；综述<br>
    注：本文已由机器之心翻译，可供参考 [链接](https://www.jiqizhixin.com/articles/1529c920-78fa-49d5-8649-c5aed28efb9b)<br>
推荐人：李垠桥
    
-----
* [Bringing HPC Techniques to Deep Learning](http://research.baidu.com/bringing-hpc-techniques-deep-learning/)
     
    本文针对数据并行训练神经网络中，大量传输耗时导致加速比较偏低的现象进行改进，引入All-Reduce算法对其进行加速，降低多设备训练对传输速度的影响。<br>
    tag：数据并行；数据传输；多设备；All-Reduce<br>
    注：本文已由机器之心翻译，可供参考 [链接](https://www.jiqizhixin.com/articles/61ad2d69-8eae-47b6-bcdd-fe2d853b7c20)<br>
推荐人：李垠桥
    
-----
